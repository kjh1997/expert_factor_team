{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ca35374",
   "metadata": {},
   "source": [
    "# Step 1: IMPORT THE LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f969ef91",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _jpype: DLL 초기화 루틴을 실행할 수 없습니다.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19084/2013958058.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkonlpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOkt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpymongo\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMongoClient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\konlpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkonlpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjvm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minit_jvm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m from konlpy import (\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\konlpy\\tag\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkonlpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hannanum\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHannanum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkonlpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_kkma\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKkma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkonlpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_komoran\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKomoran\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\konlpy\\tag\\_hannanum.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mjpype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkonlpy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjvm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\jpype\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# *****************************************************************************\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0m_jpype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_jinit\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_jpackage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _jpype: DLL 초기화 루틴을 실행할 수 없습니다."
     ]
    }
   ],
   "source": [
    "import re\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "from gensim import corpora\n",
    "from pymongo import MongoClient\n",
    "from bson.objectid import ObjectId"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aae0a01",
   "metadata": {},
   "source": [
    "# Step 2: CONNECTION TO THE DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d73c1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('mongodb://203.255.92.141:27017', authSource='admin')\n",
    "db = client['SCIENCEON']\n",
    "db.list_collection_names()\n",
    "scienceOn_author = db['Author']\n",
    "scienceOn_authorPapers = db['AuthorPapers']\n",
    "scienceOn_rawData = db['Rawdata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cdd702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.0\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "print(tweepy.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cb2261",
   "metadata": {},
   "source": [
    "# Step 3: FIND THE AUTHOR RESEARCH ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3211ec80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s101957\n"
     ]
    }
   ],
   "source": [
    "author_cursor = scienceOn_author.find({'name':'유재수', 'inst': '충북대학교'})\n",
    "for author in author_cursor:\n",
    "    researcher_ID = author['_id']\n",
    "print(researcher_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fab2cc4",
   "metadata": {},
   "source": [
    "# Step 4: FIND ALL THE PAPERS OF THE AUTHOR HAVING THE RESEARCH ID WE FOUND & PUT IT IN A DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744bff44",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPapers = pd.DataFrame(columns=['papers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b2302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "authorPapers_cursor = scienceOn_authorPapers.find({'A_ID':researcher_ID})\n",
    "for authorPapers in authorPapers_cursor:\n",
    "    papers = authorPapers['papers']\n",
    "    for i in range(len(papers)):\n",
    "        papersID = papers[i]\n",
    "        objInstance = ObjectId(papersID)\n",
    "        rawData_cursor = scienceOn_rawData.find({ \"_id\" : objInstance })\n",
    "        for document in rawData_cursor:\n",
    "            if type(document['paper_keyword']) != list:\n",
    "                new_document = document['title'] + ' ' + document['english_title'] + ' ' + document['abstract'] + ' ' + document['paper_keyword'] + ' ' + document['english_abstract']\n",
    "            else:\n",
    "                paper_keyword = ''\n",
    "                for j in range(len(document['paper_keyword'])):\n",
    "                    paper_keyword += document['paper_keyword'][j] + ' '\n",
    "                new_document = document['title'] + ' ' + document['english_title'] + ' ' + document['abstract'] + paper_keyword + document['english_abstract']\n",
    "            df_new_document = pd.DataFrame(data=np.array([[new_document]]), columns=['papers'])\n",
    "            dfPapers = pd.concat([dfPapers,df_new_document], ignore_index=True)\n",
    "documents = dfPapers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ab6ec7",
   "metadata": {},
   "source": [
    "# Step 5: PRINT THE DATAFRAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537f8aee",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb61164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    hdfs에서 적응형 캐시 관리 기법 adaptive cache management ...\n",
       "1    이미지 데이터 마이닝을 이용한 모바일 기반 금형 검색 시스템 a mold searc...\n",
       "2    빅데이터 활성화 정책 및 응용 사례    다양한 정보 채널의 등장과 함께 빅데이터에...\n",
       "3                               빅데이터 병렬 처리 기술 동향      \n",
       "4                                 4차 산업혁명에서 빅데이터      \n",
       "Name: papers, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuation\n",
    "documents['papers'] = documents['papers'].map(lambda x: re.sub(r'[^\\w\\s]',' ',x))\n",
    "\n",
    "# Convert the titles to lowercase\n",
    "documents['papers'] = documents['papers'].map(lambda x: x.lower())\n",
    "\n",
    "# Print out the first rows of papers\n",
    "documents['papers'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fed554c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>papers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hdfs에서 적응형 캐시 관리 기법 adaptive cache management ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이미지 데이터 마이닝을 이용한 모바일 기반 금형 검색 시스템 a mold searc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>빅데이터 활성화 정책 및 응용 사례    다양한 정보 채널의 등장과 함께 빅데이터에...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>빅데이터 병렬 처리 기술 동향</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4차 산업혁명에서 빅데이터</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>화장품 추천을 위한 개인의 피부 유형 및 유전자를 이용한 빅데이터 분석 기반 모바일...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nosql 데이터베이스 엔진을 이용한 스토리지 벤치마킹 시스템 storage ben...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>노화 관련 유전자의 후성유전학적 접근 epigenomic approaches for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>이미지 데이터 마이닝을 이용한 모바일 기반 금형 검색 시스템 a mold searc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ycsb 기반의 데이터베이스 엔진 벤치마킹 gui 설계 design of gui f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nosql 데이터베이스 엔진을 이용한 스토리지 벤치마킹 시스템 storage ben...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>그래프 데이터 기반의 지반 탐사 시스템 a ground discovery syste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>스트림 그래프에서 서브 그래프 패턴 분석을 이용한 이상 패턴 감지 anomaly d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>구조적 차이를 고려한 서브 그래프 매칭을 위한 요약 색인 기법 summary ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>화장품 추천을 위한 개인의 피부 유형 및 유전자를 이용한 빅데이터 분석 기반 모바일...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>전자상거래에서 상품 신뢰도를 고려한 개인화 추천 personalized recomm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>스트림 그래프에서 서브 그래프 패턴 분석을 이용한 이상 패턴 감지 anomaly d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>구조적 차이를 고려한 서브 그래프 매칭을 위한 요약 색인 기법 summary ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>간선 유형 및 가중치를 고려한 연속 서브 그래프 매칭 기법 continuous su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>그래프 스트림에서 효율적인 근사 top k 서브 그래프 매칭 기법 efficient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ycsb 기반의 데이터베이스 엔진 벤치마킹 gui 설계 design of gui f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>nosql 데이터베이스 엔진을 이용한 스토리지 벤치마킹 시스템 storage ben...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ycsb 기반의 데이터베이스 엔진 벤치마킹 gui 설계 design of gui f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>nosql 데이터베이스 엔진을 이용한 스토리지 벤치마킹 시스템 storage ben...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>화장품 추천을 위한 개인의 피부 유형 및 유전자를 이용한 빅데이터 분석 기반 모바일...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               papers\n",
       "0   hdfs에서 적응형 캐시 관리 기법 adaptive cache management ...\n",
       "1   이미지 데이터 마이닝을 이용한 모바일 기반 금형 검색 시스템 a mold searc...\n",
       "2   빅데이터 활성화 정책 및 응용 사례    다양한 정보 채널의 등장과 함께 빅데이터에...\n",
       "3                              빅데이터 병렬 처리 기술 동향      \n",
       "4                                4차 산업혁명에서 빅데이터      \n",
       "5   화장품 추천을 위한 개인의 피부 유형 및 유전자를 이용한 빅데이터 분석 기반 모바일...\n",
       "6   nosql 데이터베이스 엔진을 이용한 스토리지 벤치마킹 시스템 storage ben...\n",
       "7   노화 관련 유전자의 후성유전학적 접근 epigenomic approaches for...\n",
       "8   이미지 데이터 마이닝을 이용한 모바일 기반 금형 검색 시스템 a mold searc...\n",
       "9   ycsb 기반의 데이터베이스 엔진 벤치마킹 gui 설계 design of gui f...\n",
       "10  nosql 데이터베이스 엔진을 이용한 스토리지 벤치마킹 시스템 storage ben...\n",
       "11  그래프 데이터 기반의 지반 탐사 시스템 a ground discovery syste...\n",
       "12  스트림 그래프에서 서브 그래프 패턴 분석을 이용한 이상 패턴 감지 anomaly d...\n",
       "13  구조적 차이를 고려한 서브 그래프 매칭을 위한 요약 색인 기법 summary ind...\n",
       "14  화장품 추천을 위한 개인의 피부 유형 및 유전자를 이용한 빅데이터 분석 기반 모바일...\n",
       "15  전자상거래에서 상품 신뢰도를 고려한 개인화 추천 personalized recomm...\n",
       "16  스트림 그래프에서 서브 그래프 패턴 분석을 이용한 이상 패턴 감지 anomaly d...\n",
       "17  구조적 차이를 고려한 서브 그래프 매칭을 위한 요약 색인 기법 summary ind...\n",
       "18  간선 유형 및 가중치를 고려한 연속 서브 그래프 매칭 기법 continuous su...\n",
       "19  그래프 스트림에서 효율적인 근사 top k 서브 그래프 매칭 기법 efficient...\n",
       "20  ycsb 기반의 데이터베이스 엔진 벤치마킹 gui 설계 design of gui f...\n",
       "21  nosql 데이터베이스 엔진을 이용한 스토리지 벤치마킹 시스템 storage ben...\n",
       "22  ycsb 기반의 데이터베이스 엔진 벤치마킹 gui 설계 design of gui f...\n",
       "23  nosql 데이터베이스 엔진을 이용한 스토리지 벤치마킹 시스템 storage ben...\n",
       "24  화장품 추천을 위한 개인의 피부 유형 및 유전자를 이용한 빅데이터 분석 기반 모바일..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b582e9",
   "metadata": {},
   "source": [
    "# LDA PART"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2770ffc",
   "metadata": {},
   "source": [
    "# Step 1: Data Cleaning & Prepare text for LDA analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fdab1d",
   "metadata": {},
   "source": [
    "DataFrame to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fff06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hdfs에서 적응형 캐시 관리 기법 adaptive cache management scheme in hdfs 스마트팩토리는 정보통신기술 ict 를 이용한 공정의 모든 데이터를 수집  분석하여 제어하고 있다  기존보다 방대한 양의 데이터를 처리하기 위해 기업들은 하둡을 이용한다  다양한 크기의 데이터가 나타나는 환경에서 hdfs을 효율적으로 관리하기 위한 적응형 캐시 관리 기법을 제안한다  제안하는 기법은 데이터 노드의 로컬 디스크의 공간 이용 효율성을 높이고 평균 데이터 크기를 분석하여 데이터 노드 확장시 적합한 블록 크기를 적용할 수 있게 관리한다  성능 평가를 통해 제안하는 기법의 데이터 노드에서 로컬 디스크 효율 향상과 읽기와 쓰기 속도의 속도에 효과를 보인다 '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_documents = list(documents['papers'])\n",
    "list_of_documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3a5bf6",
   "metadata": {},
   "source": [
    "Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebeb0f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "java.lang.UnsatisfiedLinkError: Can't load library: C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_jpype.cp39-win_amd64.pyd",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2440/2417072802.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOkt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstem\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#t.pos(d, stem=True, norm=True) or t.nouns(d)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtexts_ko\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist_of_documents\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts_ko\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\konlpy\\tag\\_okt.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, jvmpath, max_heap_size)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjvmpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_heap_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mjpype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misJVMStarted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[0mjvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_jvm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjvmpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_heap_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0moktJavaPackage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjpype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJPackage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'kr.lucypark.okt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\konlpy\\jvm.py\u001b[0m in \u001b[0;36minit_jvm\u001b[1;34m(jvmpath, max_heap_size)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mjvmpath\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         jpype.startJVM(jvmpath, '-Djava.class.path=%s' % classpath,\n\u001b[0m\u001b[0;32m     65\u001b[0m                                 \u001b[1;34m'-Dfile.encoding=UTF8'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                                 \u001b[1;34m'-ea'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-Xmx{}m'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_heap_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\jpype\\_core.py\u001b[0m in \u001b[0;36mstartJVM\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mSystemError\u001b[0m: java.lang.UnsatisfiedLinkError: Can't load library: C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_jpype.cp39-win_amd64.pyd"
     ]
    }
   ],
   "source": [
    "t = Okt()\n",
    "pos = lambda d: ['/'.join(p) for p in t.pos(d, stem=True, norm=True)] #t.pos(d, stem=True, norm=True) or t.nouns(d)\n",
    "texts_ko = [pos(doc) for doc in list_of_documents]\n",
    "print(texts_ko[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9057a8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.9.6 (tags/v3.9.6:db3ff76, Jun 28 2021, 15:26:21) [MSC v.1929 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879c3fcf",
   "metadata": {},
   "source": [
    "Encode tokens to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c09a21a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'texts_ko' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4140/1679252769.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdictionary_ko\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts_ko\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdictionary_ko\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ko.dict'\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# save dictionary to file for future use\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'texts_ko' is not defined"
     ]
    }
   ],
   "source": [
    "dictionary_ko = corpora.Dictionary(texts_ko)\n",
    "dictionary_ko.save('ko.dict')  # save dictionary to file for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c2c94f",
   "metadata": {},
   "source": [
    "Calculate TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee419ea9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'texts_ko' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4140/2435285160.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#from gensim import models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtf_ko\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdictionary_ko\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtexts_ko\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtfidf_model_ko\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTfidfModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf_ko\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtfidf_ko\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf_model_ko\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtf_ko\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMmCorpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ko.mm'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtfidf_ko\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# save corpus to file for future use\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'texts_ko' is not defined"
     ]
    }
   ],
   "source": [
    "#from gensim import models\n",
    "tf_ko = [dictionary_ko.doc2bow(text) for text in texts_ko]\n",
    "tfidf_model_ko = gensim.models.TfidfModel(tf_ko)\n",
    "tfidf_ko = tfidf_model_ko[tf_ko]\n",
    "corpora.MmCorpus.serialize('ko.mm', tfidf_ko) # save corpus to file for future use\n",
    "\n",
    "# print first 10 elements of first document's tf-idf vector\n",
    "print(tfidf_ko.corpus[0][:10])\n",
    "# print top 10 elements of first document's tf-idf vector\n",
    "print(sorted(tfidf_ko.corpus[0], key=lambda x: x[1], reverse=True)[:10])\n",
    "# print token of most frequent element\n",
    "print(dictionary_ko.get(27))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5add6d09",
   "metadata": {},
   "source": [
    "# Step 3: LDA model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd789e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(corpus=tfidf_ko,\n",
    "                                       id2word=dictionary_ko,\n",
    "                                       num_topics=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ece5056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.007*\"병렬/Noun\" + 0.007*\"동향/Noun\" + 0.006*\"처리/Noun\" + 0.005*\"k/Alpha\" + 0.005*\"top/Alpha\"'),\n",
       " (1,\n",
       "  '0.018*\"지/Josa\" + 0.018*\"스토리/Noun\" + 0.011*\"벤치마킹/Noun\" + 0.011*\"nosql/Alpha\" + 0.007*\"엔진/Noun\"'),\n",
       " (2,\n",
       "  '0.006*\"피부/Noun\" + 0.005*\"금/Noun\" + 0.004*\"벤치마킹/Noun\" + 0.004*\"형/Suffix\" + 0.004*\"gui/Alpha\"'),\n",
       " (3,\n",
       "  '0.007*\"4/Number\" + 0.006*\"차/Noun\" + 0.006*\"산업혁명/Noun\" + 0.006*\"패턴/Noun\" + 0.006*\"피부/Noun\"'),\n",
       " (4,\n",
       "  '0.008*\"색인/Noun\" + 0.007*\"그래프/Noun\" + 0.005*\"패턴/Noun\" + 0.005*\"유전자/Noun\" + 0.005*\"요약/Noun\"')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = lda_model.print_topics(-1,5)\n",
    "keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6b5672",
   "metadata": {},
   "source": [
    "# KEYWORD PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b914d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = []\n",
    "for topic in lda_model.print_topics(-1,5):\n",
    "    topic_list = topic[1].split('+')\n",
    "    for i in range(len(topic_list)):\n",
    "        count = 0\n",
    "        words = topic_list[i].split('\"')\n",
    "        for j in range(len(words)):\n",
    "            if \"*\" in words[j] or words[j] == \"\" or words[j] == \" \":\n",
    "                continue\n",
    "            elif words[j] not in keywords:\n",
    "                word = words[j].split('/')\n",
    "                if word[0] not in keywords and word[1] == \"Noun\":\n",
    "                    count += 1\n",
    "                    keywords.append(word[0])\n",
    "                    break\n",
    "        if count >= 1:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ea1382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['상품', '피부', '색인', '병렬', '스토리']\n"
     ]
    }
   ],
   "source": [
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e7ffa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
