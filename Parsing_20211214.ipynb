{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEARCH0. 참고 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authorSize = self.dbs['AuthorPapers'].count({\"keyId\":keyId})\n",
    "\n",
    "# th = 100 # each core handle 100 or more data\n",
    "# sizeDict = {}\n",
    "# perData = int(authorSize / self.cores)\n",
    "# if perData > th :\n",
    "#     last = 0\n",
    "#     for i in range(self.cores-1) :\n",
    "#         sizeDict[last] = last+perData\n",
    "#         last += perData\n",
    "#     sizeDict[last] = authorSize\n",
    "# else :\n",
    "#     sizeDict[0] = authorSize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sizeDict[0] 로그찍어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processList = []\n",
    "# for key in sizeDict :\n",
    "#     acl = None\n",
    "#     if self.site == 'NTIS':\n",
    "#         acl = analyzerProject(keyId, self.site, qryResult, key, sizeDict[key], authorSize)\n",
    "    \n",
    "#     else :\n",
    "#         acl = analyzerPaper(keyId, self.site, qryResult, key, sizeDict[key], authorSize)\n",
    "    \n",
    "#     p = Process(target= acl.run)\n",
    "#     processList.append(p)\n",
    "#     p.start()\n",
    "# for p in processList :\n",
    "#     p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEARCH1. MULTIPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from multiprocessing import Process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('203.255.92.141:27017', connect=False)\n",
    "id = client['ID']\n",
    "domestic = client['ID']['Domestic']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseContext.cpu_count of <multiprocessing.context.DefaultContext object at 0x000002C41C5E5B80>>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiprocessing.cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "authorSize = domestic.count_documents({\"fid\":0, \"keyId\" :588})\n",
    "\n",
    "th = 100 # each core handle 100 or more data\n",
    "sizeDict = {}\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "if cores > 3:\n",
    "    cores -= 1\n",
    "perData = int(authorSize / cores)\n",
    "\n",
    "if perData > th :\n",
    "    last = 0\n",
    "    for i in range(cores-1) :\n",
    "        sizeDict[last] = last+perData\n",
    "        last += perData\n",
    "    sizeDict[last] = authorSize\n",
    "else :\n",
    "    sizeDict[0] = authorSize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88902\n",
      "11112\n",
      "12700\n",
      "{0: 12700, 12700: 25400, 25400: 38100, 38100: 50800, 50800: 63500, 63500: 76200, 76200: 88902}\n"
     ]
    }
   ],
   "source": [
    "print(authorSize)\n",
    "print(int(authorSize/8))\n",
    "print(sizeDict[0]) #로그찍어보기\n",
    "print(sizeDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEARCH2. 통합지수 분석기 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "import threading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Analysis(threading.Thread):\n",
    "\n",
    "#     client =  MongoClient('localhost:27017', connect=False)\n",
    "#     db = None\n",
    "#     dt = datetime.datetime.now()\n",
    "#     AuthorRelation = None\n",
    "#     QueryKeyword = None\n",
    "#     AuthorPapers  = None\n",
    "#     ExpertFactor  = None\n",
    "#     Author = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class intergratingAnalyzer(threading.Thread):\n",
    "    client =  MongoClient('localhost:27017', connect=False)\n",
    "    db = None\n",
    "    # dt = datetime.datetime.now()\n",
    "\n",
    "    def __init__(self, _keyId, _fid, _query, _start, _end, _total):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.keyId        = _keyId\n",
    "        self.fid          = _fid\n",
    "        self.defaultScore = 0.02\n",
    "        self.start        = _start\n",
    "        self.end          = _end\n",
    "        self.total        = _total\n",
    "        self.query        = _query\n",
    "    \n",
    "    def run(self):\n",
    "        print(\"---------------------\")\n",
    "        print(self.start)\n",
    "        print(self.end)\n",
    "        print(self.total)\n",
    "        print(\"---------------------\")\n",
    "        \"\"\" #3. DB client 생성 \"\"\"\n",
    "        # self.initDBs()\n",
    "        # All_count = self.end - self.start\n",
    "        # dataPerPage = 100\n",
    "\n",
    "        # self.dt = datetime.datetime.now()\n",
    "        # print('start', self.dt)\n",
    "        # tempQty  = -1\n",
    "        # tempCont = -1\n",
    "        # tempQual = -1\n",
    "        # tempCoop = -1\n",
    "        # maxFactors = {'Quality' : -1, 'Productivity' : -1, 'Contrib' : -1 }\n",
    "        # factorVars = {'Quality' : 'tempQual', 'Productivity' : 'tempQty', 'Contrib' : 'tempCont' }\n",
    "        # if self.site != 'NTIS' :\n",
    "        #     maxFactors['Coop'] = -1\n",
    "        #     factorVars['Coop'] = 'tempCoop'\n",
    "    \n",
    "    # def initDBs(self) :\n",
    "    #     global AuthorRelation, QueryKeyword, AuthorPapers, ExpertFactor, Author, Rawdata, db2, public_QueryKeyword, KCI, SCI, ExpertFactorTable\n",
    "\n",
    "    #     db                  = self.client[self.site]\n",
    "    #     db2                 = self.client.PUBLIC\n",
    "    #     public_QueryKeyword = db2.QueryKeyword\n",
    "    #     AuthorRelation      = db.AuthorRelation\n",
    "    #     QueryKeyword        = db.QueryKeyword\n",
    "    #     AuthorPapers        = db.AuthorPapers\n",
    "    #     ExpertFactor        = db.ExpertFactor\n",
    "    #     Author              = db.Author\n",
    "    #     Rawdata             = db.Rawdata\n",
    "    #     KCI                 = db2.KCI\n",
    "    #     SCI                 = db2.SCI\n",
    "    #     ExpertFactorTable   = db.ExpertFactorTable\n",
    "\n",
    "    #     self.kDic = {}\n",
    "    #     self.sDic = {}\n",
    "    #     for doc in KCI.find({}) :\n",
    "    #         self.kDic[doc['name']] = doc['IF']\n",
    "    #     for doc in SCI.find({}) :\n",
    "    #         self.sDic[doc['name']] = doc['IF']\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Process name='Process-1' parent=14088 initial>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot pickle '_thread.lock' object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-160-7dbcb3349f30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprocessList\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprocessList\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    119\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot pickle '_thread.lock' object"
     ]
    }
   ],
   "source": [
    "keyId = 1\n",
    "\n",
    "\n",
    "processList = []\n",
    "for i in sizeDict :\n",
    "    acl = intergratingAnalyzer(keyId, 0, \"test\", i, sizeDict[i], authorSize)\n",
    "\n",
    "    p = Process(target= acl.run)\n",
    "    processList.append(p)\n",
    "    print(p)\n",
    "    p.start()\n",
    "for p in processList :\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEARCH3. 분석기 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" #2. 분석기 실행 \"\"\"\n",
    "def run(self):\n",
    "\n",
    "        \"\"\" #3. DB client 생성 \"\"\"\n",
    "        self.initDBs()\n",
    "        All_count = self.end - self.start\n",
    "        dataPerPage = 100\n",
    "\n",
    "        # self.dt = datetime.datetime.now()\n",
    "        print('start', self.dt)\n",
    "        tempQty  = -1\n",
    "        tempCont = -1\n",
    "        tempQual = -1\n",
    "        tempCoop = -1\n",
    "        maxFactors = {'Quality' : -1, 'Productivity' : -1, 'Contrib' : -1 }\n",
    "        factorVars = {'Quality' : 'tempQual', 'Productivity' : 'tempQty', 'Contrib' : 'tempCont' }\n",
    "        if self.site != 'NTIS' :\n",
    "            maxFactors['Coop'] = -1\n",
    "            factorVars['Coop'] = 'tempCoop'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run(self):\n",
    "\n",
    "#         \"\"\" #3. DB client 생성 \"\"\"\n",
    "#         self.initDBs()\n",
    "#         All_count = self.end - self.start\n",
    "#         dataPerPage = 100\n",
    "\n",
    "#         self.dt = datetime.datetime.now()\n",
    "#         print('start', self.dt)\n",
    "#         tempQty  = -1\n",
    "#         tempCont = -1\n",
    "#         tempQual = -1\n",
    "#         tempCoop = -1\n",
    "#         maxFactors = {'Quality' : -1, 'Productivity' : -1, 'Contrib' : -1 }\n",
    "#         factorVars = {'Quality' : 'tempQual', 'Productivity' : 'tempQty', 'Contrib' : 'tempCont' }\n",
    "#         if self.site != 'NTIS' :\n",
    "#             maxFactors['Coop'] = -1\n",
    "#             factorVars['Coop'] = 'tempCoop'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
